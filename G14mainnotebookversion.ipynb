{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed286a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/5fx_0z8s6bv_0tb_tmhs7pk00000gn/T/ipykernel_29495/911933074.py:10: DeprecationWarning: Please use `mode` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import mode\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "#import requests\n",
    "import pandas as pd\n",
    "from skimage import morphology\n",
    "from skimage.color import rgb2hsv\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats.stats import mode\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "#import seaborn as sns\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4be898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data into the notebook\n",
    "image_folder = \n",
    "segmented_image_folder = \n",
    "features  = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files =\n",
    "segmented_image_file= \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26196d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color_extraction\n",
    "def extract_red_scale(image):\n",
    "    # Convert image to HSV color space\n",
    "    #hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    bw_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    red = [255, 0, 0]  # RGB\n",
    "    diff = 50\n",
    "    boundaries = [([red[0]-diff, red[1]-diff, red[2]-diff]),     ([red[0]+diff, red[1]+diff, red[2]+diff])]\n",
    "    \n",
    "    lower_red = np.array([1,0,0])\n",
    "    upper_red = np.array([255,110,110])\n",
    "    red_mask = cv2.inRange(rgb_image, lower_red, upper_red)\n",
    "\n",
    "    output_red = rgb_image.copy()\n",
    "    output_red[np.where(red_mask==0)] = 0\n",
    "                         \n",
    "    plt.imshow(output_red)\n",
    "    plt.grid(None)\n",
    "    \n",
    "    #red_mask = cv2.inRange(image, lower_red, upper_red)\n",
    "    # Compute the percentage of red pixels\n",
    "    red_pixel_count = cv2.countNonZero(red_mask)\n",
    "    total_pixels = cv2.countNonZero(mask)\n",
    "    red_percentage = red_pixel_count / total_pixels\n",
    "    print(red_pixel_count)\n",
    "    # Map red percentage to the desired scale\n",
    "    \n",
    "    if red_percentage< 0.05:\n",
    "        red_scale = 0\n",
    "    elif red_percentage < 0.2:\n",
    "        red_scale = 1\n",
    "    elif red_percentage < 0.4:\n",
    "        red_scale = 2\n",
    "    elif red_percentage < 0.6:\n",
    "        red_scale = 3\n",
    "    else:\n",
    "        red_scale = 4\n",
    "    print((image.shape[0] * image.shape[1])-cv2.countNonZero(bw_image))\n",
    "    print(cv2.countNonZero(bw_image))\n",
    "    return red_scale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_yellow_scale(image):\n",
    "    # Convert image to HSV color space\n",
    "    #hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    bw_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    yellow = [255, 255, 0]  # RGB\n",
    "    diff = 50\n",
    "    boundaries = [([yellow[0]-diff, yellow[1]-diff, yellow[2]-diff]),\n",
    "                  ([yellow[0]+diff, yellow[1]+diff, yellow[2]+diff])]\n",
    "    \n",
    "    lower_yellow = np.array([220,120,120])\n",
    "    upper_yellow = np.array([255,255,255])\n",
    "    yellow_mask = cv2.inRange(rgb_image, lower_yellow, upper_yellow)\n",
    "\n",
    "    output_yellow = rgb_image.copy()\n",
    "    output_yellow[np.where(yellow_mask==0)] = 0\n",
    "                         \n",
    "    plt.imshow(output_yellow)\n",
    "    plt.grid(None)\n",
    "    \n",
    "    #red_mask = cv2.inRange(image, lower_red, upper_red)\n",
    "    # Compute the percentage of red pixels\n",
    "    yellow_pixel_count = cv2.countNonZero(yellow_mask)\n",
    "    total_pixels = cv2.countNonZero(mask)\n",
    "    yellow_percentage = yellow_pixel_count / total_pixels\n",
    "    print(yellow_pixel_count)\n",
    "    # Map red percentage to the desired scale\n",
    "    \n",
    "    if yellow_percentage < 0.05:\n",
    "        yellow_scale = 0\n",
    "    elif yellow_percentage < 0.2:\n",
    "        yellow_scale = 1\n",
    "    elif yellow_percentage < 0.4:\n",
    "        yellow_scale = 2\n",
    "    elif yellow_percentage < 0.6:\n",
    "        yellow_scale = 3\n",
    "    else:\n",
    "        yellow_scale = 4\n",
    "    print((image.shape[0] * image.shape[1])-cv2.countNonZero(bw_image))\n",
    "    print(cv2.countNonZero(bw_image))\n",
    "    return yellow_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998cab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_purple_scale(image):\n",
    "    # Convert image to HSV color space\n",
    "    #hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    bw_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    purple = [255, 255, 0]  # RGB\n",
    "    diff = 50\n",
    "    boundaries = [([purple[0]-diff, purple[1]-diff, purple[2]-diff]),\n",
    "                  ([purple[0]+diff, purple[1]+diff, purple[2]+diff])]\n",
    "    \n",
    "    lower_purple = np.array([50,99,0])\n",
    "    upper_purple = np.array([130,100,255])\n",
    "    purple_mask = cv2.inRange(rgb_image, lower_purple, upper_purple)\n",
    "\n",
    "    output_purple = rgb_image.copy()\n",
    "    output_purple[np.where(purple_mask==0)] = 0\n",
    "                         \n",
    "    plt.imshow(output_purple)\n",
    "    plt.grid(None)\n",
    "    \n",
    "    #red_mask = cv2.inRange(image, lower_red, upper_red)\n",
    "    # Compute the percentage of red pixels\n",
    "    purple_pixel_count = cv2.countNonZero(purple_mask)\n",
    "    total_pixels = cv2.countNonZero(bw_image)\n",
    "    purple_percentage = purple_pixel_count / total_pixels\n",
    "    print(purple_pixel_count)\n",
    "    # Map red percentage to the desired scale\n",
    "    \n",
    "    if purple_percentage < 0.05:\n",
    "        purple_scale = 0\n",
    "    elif purple_percentage < 0.2:\n",
    "        purple_scale = 1\n",
    "    elif purple_percentage < 0.4:\n",
    "        purple_scale = 2\n",
    "    elif purple_percentage < 0.6:\n",
    "        purple_scale = 3\n",
    "    else:\n",
    "        purple_scale = 4\n",
    "    print(cv2.countNonZero(bw_image))\n",
    "    print(total_pixels)\n",
    "    return purple_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb240e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brown_scale(image):\n",
    "    # Convert image to HSV color space\n",
    "    #hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    bw_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    brown = [255, 255, 0]  # RGB\n",
    "    diff = 50\n",
    "    boundaries = [([brown[0]-diff, brown[1]-diff, brown[2]-diff]),\n",
    "                  ([brown[0]+diff, brown[1]+diff, brown[2]+diff])]\n",
    "    \n",
    "    lower_brown = np.array([50,0,0])\n",
    "    upper_brown= np.array([150,200,100])\n",
    "    brown_mask = cv2.inRange(rgb_image, lower_brown, upper_brown)\n",
    "\n",
    "    output_brown = rgb_image.copy()\n",
    "    output_brown[np.where(brown_mask==0)] = 0\n",
    "                         \n",
    "    plt.imshow(output_brown)\n",
    "    plt.grid(None)\n",
    "    \n",
    "    #red_mask = cv2.inRange(image, lower_red, upper_red)\n",
    "    # Compute the percentage of red pixels\n",
    "    brown_pixel_count = cv2.countNonZero(brown_mask)\n",
    "    total_pixels = cv2.countNonZero(bw_image)\n",
    "    brown_percentage = brown_pixel_count / total_pixels\n",
    "    print(brown_pixel_count)\n",
    "    # Map red percentage to the desired scale\n",
    "    \n",
    "    if brown_percentage < 0.05:\n",
    "        brown_scale = 0\n",
    "    elif brown_percentage < 0.2:\n",
    "        brown_scale = 1\n",
    "    elif brown_percentage < 0.4:\n",
    "        brown_scale = 2\n",
    "    elif brown_percentage < 0.6:\n",
    "        brown_scale = 3\n",
    "    else:\n",
    "        brown_scale = 4\n",
    "    print(cv2.countNonZero(bw_image))\n",
    "    print(total_pixels)\n",
    "    return brown_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539280ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetry_extraction(im):\n",
    "    #01.read the image using the Matplotlib library \n",
    "    im = plt.imread(im)\n",
    "\n",
    "    #02.Crop the image : this is done by finding the indices of the non zero elements(pixels with non zero intensity values)\n",
    "    #in order to do that,here we use np.nonezero from the numpy library \n",
    "    #center of the  shape is the center of the image\n",
    "    #the boarders of the shape are the boaders of the image\n",
    "    y_nonzero, x_nonzero = np.nonzero(im)\n",
    "    im = im[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)] #slice the image to include only the non zero regions\n",
    "\n",
    "    #03.Cut the image in halves\n",
    "    #04.Find the point of cutoff\n",
    "    height, width = im.shape\n",
    "    cutoff_of_width = width//2\n",
    "    cutoff_of_height  = height // 2\n",
    "\n",
    "    #05.Cut the image vertically and horizontally in two\n",
    "    vertical1_im = im[:,:cutoff_of_width]\n",
    "    vertical2_im = im[:,cutoff_of_width:]\n",
    "    horizontal1_im = im[:cutoff_of_height,:]\n",
    "    horizontal2_im = im[cutoff_of_height:,:]\n",
    "\n",
    "    #Simply put, in step 03, 04 and 05, cuts the cropped image into four sections: top, bottom , left and right.\n",
    "    #This is done by dividing the width and height of the image by 2 and using the resulting values to slice the image horizontally and vertically\n",
    "\n",
    "\n",
    "    #06.Flip one of the images both vertically and horizontally to create mirror images for each of the four sections.\n",
    "    # This is done by NumPy array indexing with negative  step size to reverse the order of elements along the specified axis. \n",
    "    vertical_indexer = [slice(None)]*vertical2_im.ndim\n",
    "    horizontal_indexer = [slice(None)]*horizontal2_im.ndim\n",
    "    #Here, slice(None) creates a slice object that includes all elements along the specified axis, and imVertical2.ndim and imHorizontal2.ndim retrun the number of dimensions of the respective arrays.\n",
    "    #create two lists of slice objects with the same lenght as the number of dimesnions of the corresponding arrays.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    vertical_indexer[1]= slice(None,None, -1)\n",
    "    vertical_indexer[0]=slice(None, None,-1)\n",
    "    #modify the slice objects in the second position  of each list to include all elements alng the corresponding axis in reverse order, using the -1 step size.\n",
    "    #This flips the array along that axis effectively\n",
    "\n",
    "\n",
    "\n",
    "    vertical2_im = vertical2_im[tuple(vertical_indexer)]\n",
    "    horizontal2_im = horizontal2_im[tuple(horizontal_indexer)]\n",
    "    #convert each list of slice objects to tuple and use it for NumPy indexing to obtain the flipped images.\n",
    "\n",
    "\n",
    "\n",
    "    #07. if the images don't have the same shape, cut the biggest image\n",
    "    #This can happen if the shape of the original shape was an odd number\n",
    "    vertical2_im =vertical2_im[0:vertical1_im.shape[0], 0:vertical1_im.shape[1]]\n",
    "    horizontal2_im = horizontal2_im[0:horizontal1_im.shape[0], 0:horizontal1_im.shape[1]]\n",
    "\n",
    "    im_bwx_vertical = cv2.bitwise_xor(vertical1_im,vertical2_im)\n",
    "    im_bwx_horizontal = cv2.bitwise_xor(horizontal1_im, horizontal2_im)\n",
    "\n",
    "    vertical_area = np.sum(im_bwx_vertical ==1)\n",
    "    horizontal_area= np.sum(im_bwx_horizontal==1)\n",
    "    mean_area = (vertical_area + horizontal_area) //2\n",
    "    #np.sum is used to count the number of white pixels in each binary image im_bwx_vertical and im_bwx_horizontal. \n",
    "    #This count is performed using the logical expresion im_bwx_vertical == 1 and im_bwx_horizontal == 1 respectively. The expression returns a Boolean array that is True where the value of im_bwx_vertical or im_bwx_horizontal is equal to 1, and False elsewhere. The np.sum() function then counts the number of True values in the array and returns the total count of white pixels in each image.\n",
    "\n",
    "\n",
    "    #Here, the asymmetry level is calculated as a percentage of the non zero pixels  in the overlapped image over the lesion area\n",
    "    return(mean_area/np.sum(im==1))*100\n",
    "    #np.sum(im==1) is used to count the toatal number of non zero( while) pixels in the original image\n",
    "    #(mean_area/np.sum(im==1))*100 calculates the asymmetry level of the  input image as a percentage.\n",
    "    #the numerator is the average area of asymmetry  between two halves of the input image, in pixels.\n",
    "    # The denominator us the total number of non zero pixels in the input image.\n",
    "    #The result is  then multiplied by 100  to convert the values in to percentage.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb902787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perimeter_area(im):\n",
    "    image = plt.imread(im)\n",
    "    mask = image.copy() #creates a copy of the original image, which will be used to create a binary mask\n",
    "    area = np.sum(mask) #calculates the area of the lesion by summing the values of all pixels in the binary mask\n",
    "    struct_el = morphology.disk(1) #cretaes  a disk shaped structuring element with a radius of 1, which wil be used for binary erosion.\n",
    "    #Binary erosion is a morphological operation used in image processing to reduce the size of foreground objects(usually represented as white pixels) and eliminate isolated pixels or small components\n",
    "    #The operation is performed by sliding a small binary structuring element (also known as kernel or mask) over the image and checking if all the pixels in the element match the corresponding pixels in the image.\n",
    "    #If there is at least one mismatch, the pixel in the center of the structuring element is set to 0 (black), otherwise it is set to 1 (white).\n",
    "    #As a result, the foreground pixels in the input image that are not completely covered by the structuring element are removed in the output image.\n",
    "    # The size of the foreground objects is thus reduced, while their shape is preserved as much as possible.\n",
    "    #The process is repeated iteratively until the foreground objects can no longer be further reduced, or until a desired level of erosion has been achieved.\n",
    "    mask_eroded = morphology.binary_erosion(mask, struct_el) #erodes the binary mask using the strucutring element, resulting in a new binary mask with the same shape as the original mask but with the edges erroded.\n",
    "    image_perimeter = mask - mask_eroded  #subtracts the eroded mask from the original mask to obtain an image that contains only the perimeter of the lesion.\n",
    "    perimeter = np.sum(image_perimeter) #caculates the perimeter of the lesion by summing the values of all pixels in the perimeter image.\n",
    "    return [area, perimeter] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and testing data : trying to split the data set into training data and  testing data\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "data_folder_path = '/Users/nuvanjanashashipraba/Desktop/Images'\n",
    "my_data = load_files(data_folder_path, categories =['folder1', 'folder2', 'folder3']) # loading the data from the folder path specified in step 3 and categorizing them into tthree folders\n",
    "\n",
    "X = my_data.data #assigning the image data to X\n",
    "Y = my_data.target #assigning the target labels to Y\n",
    "\n",
    "from sklearn.model_selection import train_test_split #importing the train_test_split function from the sklearn.model _slection library for splitting the data into trainin and testing sets.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 2)\n",
    "#splitting the data into training and testing sets, with 20% of the data set aside for testing and setting the random state for reproducibility.\n",
    "#The resulting four variables represent the training and testing data for both the image data.\n",
    "\n",
    "#print(\"The dimensions of the features of training data \")\n",
    "#print(X_train.shape)\n",
    "#print(\"The dimensions of the features of test data \")\n",
    "#print(X_test.shape)\n",
    "#print(\"The dimensions of the target values of training data \")\n",
    "#print(Y_train.shape)\n",
    "#print(\"The dimensions of the target values of test data \")\n",
    "#print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd1ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_prediction(k, train, classes, test): #classes : the class labels of the training data.\n",
    "    neighb = KNeighborsClassifier(n_neighbors= k)\n",
    "    neighb.fit(train, classes.ravel())\n",
    "    classes_pred = neighb.predict(test)\n",
    "    return classes_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac41648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(k,train,classes,test,classes_test):\n",
    "    performance = []\n",
    "    perform1 =[]\n",
    "    #the 'performance' list stores the predicted lables for each value of k\n",
    "    #the 'perform1' list stores the accuracy score for each value of k\n",
    "\n",
    "    for i in range(1,k):\n",
    "        a = make_knn_prediction(i,train,classes,test)\n",
    "        performance.append(a)\n",
    "        for j in performance:\n",
    "            b = accuracy_score(classes_test,j) #'accuracy_score' is function from scikit learn \n",
    "        perform1.append(b)\n",
    "    fig, axes = plt.subplots()\n",
    "    axes.plot(perform1)\n",
    "    plt.title(\"Classification Accuracy of KNN for Different Values of k\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.xlabel(\"Value of k\");\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=0.5)\n",
    "    return np.mean(perform1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
